{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38532d44-0ee8-48d3-b9d6-760c29ce0ff8",
   "metadata": {
    "collapsed": false,
    "name": "md_title"
   },
   "source": [
    "# Setting up the RAG Pipeline using Cortex Search\n",
    "\n",
    "In this notebook, we're setting up the RAG pipeline using the Avalanche customer review data from the previously prepared data stored in the stage. \n",
    "\n",
    "By the end of the tutorial, we'll have a RAG pipeline ready to allow us to ask any questions about the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfcb177-a3a2-45cb-b459-2e411d880e11",
   "metadata": {
    "collapsed": false,
    "name": "md_install"
   },
   "source": [
    "## Install prerequisite\n",
    "\n",
    "Make sure to have `snowflake.core` library installed by clicking on Packages in the top menu and enter `snowflake.core` into the text box."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4341b3-891c-41ee-a08c-7e012e10fa8b",
   "metadata": {
    "collapsed": false,
    "name": "md_parse_content_2"
   },
   "source": [
    "## Query parsed content\n",
    "\n",
    "Let's now query the parsed content stored in the `PARSED_CONTENT` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be400d91-e883-42d7-b26e-eb78a7219479",
   "metadata": {
    "codeCollapsed": false,
    "language": "sql",
    "name": "sql_parse_content_2"
   },
   "outputs": [],
   "source": [
    "SELECT * FROM AVALANCHE_DB.AVALANCHE_SCHEMA.PARSED_REVIEWS LIMIT 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535af127-985c-4bcb-8ffc-c0230fd8cc07",
   "metadata": {
    "collapsed": false,
    "name": "md_chunk_content"
   },
   "source": [
    "## Chunk content\n",
    "\n",
    "We'll now take the parsed data and perform chunking via `SNOWFLAKE.CORTEX.SPLIT_TEXT_RECURSIVE_CHARACTER`.\n",
    "\n",
    "Chunked content are stored at `AVALANCHE.AVALANCHE.CHUNKED_CONTENT`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1004e517-c9d3-4217-b091-74fc5750865f",
   "metadata": {
    "codeCollapsed": false,
    "language": "sql",
    "name": "sql_chunk_content"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE TABLE AVALANCHE_DB.AVALANCHE_SCHEMA.CHUNKED_CONTENT (\n",
    "    file_name VARCHAR,\n",
    "    CHUNK VARCHAR\n",
    ");\n",
    "\n",
    "INSERT INTO AVALANCHE_DB.AVALANCHE_SCHEMA.CHUNKED_CONTENT (file_name, CHUNK)\n",
    "SELECT\n",
    "    FILENAME,\n",
    "    c.value AS CHUNK\n",
    "FROM\n",
    "    AVALANCHE_DB.AVALANCHE_SCHEMA.PARSED_REVIEWS,\n",
    "    LATERAL FLATTEN( input => SNOWFLAKE.CORTEX.SPLIT_TEXT_RECURSIVE_CHARACTER (\n",
    "        CUSTOMER_REVIEW,\n",
    "        'markdown',\n",
    "        1800,\n",
    "        250\n",
    "    )) c;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b42dcf8-70ae-4c56-8171-5e56fea613ad",
   "metadata": {
    "collapsed": false,
    "name": "md_chunk_content_2"
   },
   "source": [
    "## Query chunked content\n",
    "\n",
    "Let's now query the chunked content stored in the `AVALANCHE_DB.AVALANCHE_SCHEMA.CHUNKED_CONTENT` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c3fd5b-5002-4b46-b0d7-232327da5fc4",
   "metadata": {
    "codeCollapsed": false,
    "language": "sql",
    "name": "sql_chunk_content_2"
   },
   "outputs": [],
   "source": [
    "SELECT * FROM AVALANCHE_DB.AVALANCHE_SCHEMA.CHUNKED_CONTENT LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6f71f1-51ac-4bc1-8bd0-45c28dc97cac",
   "metadata": {
    "collapsed": false,
    "name": "md_create_rag"
   },
   "source": [
    "## Create RAG pipeline with Cortex Search\n",
    "\n",
    "Here, we'll create the RAG pipeline with Cortex Search via `CORTEX SEARCH SERVICE` and this is made available at `AVALANCHE_DB.AVALANCHE_SCHEMA.AVALANCHE_SEARCH_SERVICE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72983c92-cd1f-4b6d-bc06-c65b038f3999",
   "metadata": {
    "codeCollapsed": false,
    "language": "sql",
    "name": "sql_create_rag"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE CORTEX SEARCH SERVICE AVALANCHE_DB.AVALANCHE_SCHEMA.AVALANCHE_SEARCH_SERVICE\n",
    "    ON chunk\n",
    "    WAREHOUSE = compute_wh\n",
    "    TARGET_LAG = '1 minute'\n",
    "    EMBEDDING_MODEL = 'snowflake-arctic-embed-l-v2.0'\n",
    "    AS (\n",
    "    SELECT\n",
    "        file_name,\n",
    "        chunk\n",
    "    FROM AVALANCHE_DB.AVALANCHE_SCHEMA.CHUNKED_CONTENT\n",
    "    );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340ae19f-deb0-4328-8838-10a76b0bced8",
   "metadata": {
    "collapsed": false,
    "name": "md_search_query"
   },
   "source": [
    "## RAG query\n",
    "\n",
    "Now comes the fun part, we're now going to utilize the RAG pipeline by asking a question.\n",
    "\n",
    "First, let's use SQL to perform a RAG query using `SNOWFLAKE.CORTEX.SEARCH_PREVIEW()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988ea569-dba2-402e-a727-ecb28d10e789",
   "metadata": {
    "language": "sql",
    "name": "sql_search_query"
   },
   "outputs": [],
   "source": [
    "-- Query it with SQL\n",
    "SELECT PARSE_JSON(\n",
    "  SNOWFLAKE.CORTEX.SEARCH_PREVIEW(\n",
    "      'AVALANCHE_DB.AVALANCHE_SCHEMA.AVALANCHE_SEARCH_SERVICE',\n",
    "      '{\n",
    "         \"query\": \"Any goggles review?\",\n",
    "         \"columns\":[\n",
    "            \"file_name\",\n",
    "            \"CHUNK\"\n",
    "         ],\n",
    "         \"limit\":3\n",
    "      }'\n",
    "  )\n",
    ")['results'] as results;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cc7729-d203-4861-a666-0626ad8fb707",
   "metadata": {
    "collapsed": false,
    "name": "md_search_query_2"
   },
   "source": [
    "Now, let's perform the RAG query in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d742c03-4eb2-458e-a67e-8d6b25f91151",
   "metadata": {
    "language": "python",
    "name": "py_search_query"
   },
   "outputs": [],
   "source": [
    "# Query it with Python\n",
    "from snowflake.core import Root\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "import streamlit as st\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "session = get_active_session()\n",
    "\n",
    "prompt=\"Any goggles review?\"\n",
    "\n",
    "root = Root(session)\n",
    "\n",
    "# Query service\n",
    "svc = (root\n",
    "  .databases[\"AVALANCHE_DB\"]\n",
    "  .schemas[\"AVALANCHE_SCHEMA\"]\n",
    "  .cortex_search_services[\"AVALANCHE_SEARCH_SERVICE\"]\n",
    ")\n",
    "\n",
    "resp = svc.search(\n",
    "  query=prompt,\n",
    "  columns=[\"CHUNK\", \"file_name\"],\n",
    "  limit=3\n",
    ").to_json()\n",
    "\n",
    "# JSON formatting\n",
    "json_conv = json.loads(resp) if isinstance(resp, str) else resp\n",
    "search_df = pd.json_normalize(json_conv['results'])\n",
    "\n",
    "for _, row in search_df.iterrows():\n",
    "    st.write(f\"**{row['CHUNK']}**\")\n",
    "    st.caption(row['file_name'])\n",
    "    st.write('---')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "authorEmail": "hellodataprofessor@gmail.com",
   "authorId": "7086005961584",
   "authorName": "DATAPROFESSOR",
   "lastEditTime": 1745948782914,
   "notebookId": "yoff7uddr2yzlgou3wdc",
   "sessionId": "127cf661-52e8-422a-9d6f-f6718e031fd9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
